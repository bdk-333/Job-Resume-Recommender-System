{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e739d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d2e93b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading all saved model components ---\n",
      "All components loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Loading all saved model components ---\")\n",
    "try:\n",
    "    final_model = joblib.load('../data/final_stacking_model.pkl')\n",
    "    le = joblib.load('../data/label_encoder.pkl')\n",
    "    university_map = joblib.load('../data/university_target_map.pkl')\n",
    "    all_jobs = pd.read_csv('../data/processed/all_jobs.csv')\n",
    "    \n",
    "    \n",
    "    # Load the original data to get the trained KMeans model\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    \n",
    "    df_orig = pd.read_csv('../data/processed/refined_df.csv')\n",
    "    resume_skills_c = df_orig['skills'].fillna('')\n",
    "    resume_title_c = df_orig['positions'].fillna('')\n",
    "    resume_exp_c = 'experience ' + df_orig['Resume_Years_Exp'].astype(str)\n",
    "    clustering_text = resume_skills_c + ' ' + resume_title_c + ' ' + resume_exp_c\n",
    "    tfidf_cluster = TfidfVectorizer(stop_words='english', max_features=5000, min_df=2).fit(clustering_text)\n",
    "    kmeans_model = KMeans(n_clusters=7, init='k-means++', n_init=10, random_state=42).fit(tfidf_cluster.transform(clustering_text))\n",
    "    \n",
    "    print(\"All components loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Could not find saved model files. Please run the saving code in your previous notebook first.\")\n",
    "    final_model, le, university_map, all_jobs, kmeans_model, tfidf_cluster = [None]*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e1d64ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_matrix(new_resume_dict, all_jobs_df, uni_map, kmeans, tfidf_v):\n",
    "    print(f\"Processing new resume and preparing {len(all_jobs_df)} candidate pairs...\")\n",
    "    resume_df = pd.DataFrame([new_resume_dict])\n",
    "    candidate_df = pd.merge(resume_df.assign(key=1), all_jobs_df.assign(key=1), on='key').drop('key', axis=1)\n",
    "    \n",
    "    # Apply all feature engineering steps\n",
    "    candidate_df['Experience_Mismatch'] = abs(candidate_df['Resume_Years_Exp'] - candidate_df['experience_years_required'])\n",
    "    \n",
    "    def calculate_skill_overlap(row):\n",
    "        try:\n",
    "            r_skills = set(str(row['skills']).lower().split())\n",
    "            j_skills = set(str(row['skills_required']).lower().split())\n",
    "            intersection = r_skills.intersection(j_skills)\n",
    "            union = r_skills.union(j_skills)\n",
    "            return pd.Series([len(intersection), len(intersection) / len(union) if union else 0])\n",
    "        except: return pd.Series([0, 0.0])\n",
    "    candidate_df[['Skill_Overlap_Count', 'Skill_Jaccard_Score']] = candidate_df.apply(calculate_skill_overlap, axis=1)\n",
    "\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.metrics import pairwise_distances\n",
    "    resume_text = candidate_df[['career_objective', 'skills', 'major_field_of_studies', 'positions', 'responsibilities']].fillna('').astype(str).agg(' '.join, axis=1)\n",
    "    job_text = candidate_df[['job_position_name', 'educationaL_requirements', 'skills_required', 'responsibilities.1']].fillna('').astype(str).agg(' '.join, axis=1)\n",
    "    sim_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000).fit(pd.concat([resume_text, job_text]))\n",
    "    candidate_df['Cosine_Similarity'] = 1 - pairwise_distances(sim_vectorizer.transform(resume_text), sim_vectorizer.transform(job_text), metric='cosine').diagonal()\n",
    "\n",
    "    new_resume_cluster_text = f\"{new_resume_dict.get('skills','')} {new_resume_dict.get('positions','')} experience {new_resume_dict.get('Resume_Years_Exp',0)}\"\n",
    "    new_resume_tfidf = tfidf_v.transform([new_resume_cluster_text])\n",
    "    candidate_df['Resume_Cluster_KMeans'] = kmeans.predict(new_resume_tfidf)[0]\n",
    "\n",
    "    candidate_df['gpa'] = new_resume_dict.get('gpa', 0.0)\n",
    "    candidate_df['first_university'] = new_resume_dict.get('first_university', 'Unknown')\n",
    "    candidate_df['university_encoded'] = candidate_df['first_university'].map(uni_map).fillna(uni_map.mean())\n",
    "\n",
    "    print(\"Feature matrix created successfully.\")\n",
    "    return candidate_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adcdfa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_top_n_jobs(resume_data, model, jobs_df, uni_map, label_encoder, kmeans, tfidf_v, top_n=5):\n",
    "    if model is None: print(\"Model not loaded.\"); return None\n",
    "\n",
    "    # 1. Create the feature matrix\n",
    "    feature_df = create_feature_matrix(resume_data, jobs_df, uni_map, kmeans, tfidf_v)\n",
    "    \n",
    "    final_features = ['experience_years_required', 'Skill_Overlap_Count', 'Skill_Jaccard_Score', \n",
    "                      'Resume_Years_Exp', 'Experience_Mismatch', 'Cosine_Similarity', 'gpa',\n",
    "                      'Resume_Cluster_KMeans', 'university_encoded']\n",
    "    X_predict = feature_df[final_features]\n",
    "\n",
    "    # 2. Predict probabilities for each class\n",
    "    predicted_probs = model.predict_proba(X_predict)\n",
    "    \n",
    "    # **MODIFICATION: Add probabilities for all classes to the dataframe**\n",
    "    for i, class_label in enumerate(label_encoder.classes_):\n",
    "        feature_df[f'P({class_label})'] = predicted_probs[:, i]\n",
    "\n",
    "    # 3. Rank by 'High' match probability and return the top N jobs with all probabilities\n",
    "    recommendations = feature_df.sort_values(by='P(High)', ascending=False).head(top_n)\n",
    "    \n",
    "    # Define columns to display\n",
    "    display_cols = ['job_position_name', 'P(High)', 'P(Medium)', 'P(Low)']\n",
    "    \n",
    "    return recommendations[display_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3dd5d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_resume = {\n",
    "    'career_objective': 'Seeking a challenging role in data science to apply my skills in machine learning and Python.',\n",
    "    'skills': 'Python, SQL, Scikit-learn, TensorFlow, Keras, Pandas, Matplotlib, AWS',\n",
    "    'major_field_of_studies': 'Computer Science',\n",
    "    'positions': 'Data Science Intern',\n",
    "    'responsibilities': 'Developed predictive models, built data pipelines.',\n",
    "    'Resume_Years_Exp': 1,\n",
    "    'gpa': 3.8,\n",
    "    'first_university': 'University of Illinois at Urbana-Champaign'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce1e9bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Getting Job Recommendations for Sample Resume ---\n",
      "Processing new resume and preparing 28 candidate pairs...\n",
      "Feature matrix created successfully.\n",
      "\n",
      "Top 5 Recommended Jobs:\n",
      "                                          job_position_name  P(High)  P(Medium)  P(Low)\n",
      "                                            DevOps Engineer   0.3192     0.5301  0.1508\n",
      "                               Executive/ Sr. Executive -IT   0.2283     0.5713  0.2004\n",
      "                                                AI Engineer   0.2174     0.6677  0.1149\n",
      "Intern (Generative AI Engineering - 2D/3D Image Generation)   0.2067     0.5324  0.2609\n",
      "                            Management Trainee - Mechanical   0.1682     0.6222  0.2097\n"
     ]
    }
   ],
   "source": [
    "if final_model:\n",
    "    print(\"\\n\\n--- Getting Job Recommendations for Sample Resume ---\")\n",
    "    top_jobs = recommend_top_n_jobs(sample_resume, final_model, all_jobs, university_map, le, kmeans_model, tfidf_cluster, top_n=5)\n",
    "    if top_jobs is not None:\n",
    "        print(\"\\nTop 5 Recommended Jobs:\")\n",
    "        # Format the output for better readability\n",
    "        pd.options.display.float_format = '{:.4f}'.format\n",
    "        print(top_jobs.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce88d00",
   "metadata": {},
   "source": [
    "We can see that out of 28 resumes, it has suggested related jobs as per resume. We see DevOps as the most suitable, as the skills overlap is big in this case: python, sql, AWS are very important skills in devops as well. We were also able to catch that resume intents to be an intern position and were able to suggest GEN AI intern too. Although, out of all the jobs, i think AI engineer fits the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6836be8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
