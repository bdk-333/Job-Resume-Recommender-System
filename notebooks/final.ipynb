{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99d94600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Suppress warnings for a cleaner user experience\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f75bd9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "343e571e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading helper models for feature engineering...\n",
      "\n",
      "All components loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # --- Load required libraries ---\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "    # --- Define file paths ---\n",
    "    model_path = '../data/final_adaboost_model.pkl' # <-- Your final, tuned AdaBoost pipeline\n",
    "    le_path = '../data/label_encoder.pkl'\n",
    "    uni_map_path = '../data/university_target_map.pkl'\n",
    "    svd_mean_path = '../data/mean_svd_score.pkl'\n",
    "    jobs_path = '../data/processed/all_jobs.csv'\n",
    "    \n",
    "    # --- Load artifacts ---\n",
    "    artifacts['model_pipeline'] = joblib.load(model_path)\n",
    "    artifacts['le'] = joblib.load(le_path)\n",
    "    artifacts['university_map'] = joblib.load(uni_map_path)\n",
    "    artifacts['all_jobs'] = pd.read_csv(jobs_path)\n",
    "    artifacts['mean_svd_score'] = joblib.load(svd_mean_path)\n",
    "    \n",
    "    # --- Load or re-create helper models for feature engineering ---\n",
    "    print(\"Loading helper models for feature engineering...\")\n",
    "    artifacts['embedding_model'] = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    df_orig = pd.read_csv('../data/raw/resume_data_1.csv')\n",
    "    df_orig.columns = df_orig.columns.str.strip().str.replace(r'\\ufeff', '', regex=True)\n",
    "    if 'Resume_Years_Exp' not in df_orig.columns: df_orig['Resume_Years_Exp'] = 0 # Placeholder if column is missing\n",
    "    \n",
    "    clustering_text = df_orig['skills'].fillna('') + ' ' + df_orig['positions'].fillna('') + ' experience ' + df_orig['Resume_Years_Exp'].astype(str)\n",
    "    tfidf_cluster = TfidfVectorizer(stop_words='english', max_features=5000, min_df=2).fit(clustering_text)\n",
    "    kmeans_model = KMeans(n_clusters=5, init='k-means++', n_init=10, random_state=42).fit(tfidf_cluster.transform(clustering_text))\n",
    "    \n",
    "    artifacts['kmeans_model'] = kmeans_model\n",
    "    artifacts['tfidf_cluster'] = tfidf_cluster\n",
    "\n",
    "    print(\"\\nAll components loaded successfully!\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Could not find a required file: {e.filename}\")\n",
    "    print(\"Please ensure you have run the saving code in your training notebook.\")\n",
    "    artifacts = None\n",
    "except ImportError:\n",
    "    print(\"\\nPlease install sentence-transformers: !pip install -U sentence-transformers\")\n",
    "    artifacts = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f804e9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_matrix(new_resume_dict, artifacts):\n",
    "    \"\"\" Generates the complete feature matrix for a new resume against all jobs. \"\"\"\n",
    "    print(f\"\\nProcessing new resume and preparing {len(artifacts['all_jobs'])} candidate pairs...\")\n",
    "    resume_df = pd.DataFrame([new_resume_dict])\n",
    "    candidate_df = pd.merge(resume_df.assign(key=1), artifacts['all_jobs'].assign(key=1), on='key').drop('key', axis=1)\n",
    "\n",
    "    # --- Engineer all required features ---\n",
    "    def extract_job_experience(text):\n",
    "        if isinstance(text, str):\n",
    "            match = re.search(r'(\\d+)', text.lower()); return int(match.group(1)) if match else 0\n",
    "        return 0\n",
    "    \n",
    "    candidate_df['experience_years_required'] = candidate_df['experience_years_required'].apply(extract_job_experience)\n",
    "    candidate_df['Experience_Mismatch'] = abs(candidate_df['Resume_Years_Exp'] - candidate_df['experience_years_required'])\n",
    "    \n",
    "    def process_degree_data(degree_string):\n",
    "        master_keywords = ['master', 'm.sc', 'msc', 'm.a', 'mba', 'm.com']; bachelor_keywords = ['bachelor', 'b.sc', 'bsc', 'b.tech', 'bba', 'b.a', 'b.com']; doctorate_keywords = ['ph.d', 'phd', 'doctorate']\n",
    "        stem_keywords = ['science', 'tech', 'eng', 'computer', 'math', 'statistic']; business_keywords = ['business', 'bba', 'mba', 'account', 'financ', 'commerc']; arts_keywords = ['arts', 'humanities']\n",
    "        highest_level, degree_type = 'Other', 'Other'\n",
    "        try:\n",
    "            degrees = ast.literal_eval(str(degree_string));\n",
    "            if not isinstance(degrees, list): degrees = [degrees]\n",
    "            found_levels, found_types = [], []\n",
    "            for degree in degrees:\n",
    "                degree_lower = str(degree).lower()\n",
    "                if any(k in degree_lower for k in doctorate_keywords): found_levels.append(3)\n",
    "                elif any(k in degree_lower for k in master_keywords): found_levels.append(2)\n",
    "                elif any(k in degree_lower for k in bachelor_keywords): found_levels.append(1)\n",
    "                if any(k in degree_lower for k in stem_keywords): found_types.append('STEM')\n",
    "                elif any(k in degree_lower for k in business_keywords): found_types.append('Business')\n",
    "                elif any(k in degree_lower for k in arts_keywords): found_types.append('Arts')\n",
    "            if found_levels:\n",
    "                max_level = max(found_levels);\n",
    "                if max_level == 3: highest_level = 'Doctorate'\n",
    "                elif max_level == 2: highest_level = 'Masters'\n",
    "                elif max_level == 1: highest_level = 'Bachelors'\n",
    "            if 'STEM' in found_types: degree_type = 'STEM'\n",
    "            elif 'Business' in found_types: degree_type = 'Business'\n",
    "            elif 'Arts' in found_types: degree_type = 'Arts'\n",
    "        except: pass\n",
    "        return pd.Series([highest_level, degree_type])\n",
    "    candidate_df[['highest_education_level', 'degree_type']] = candidate_df['degree_names'].apply(process_degree_data)\n",
    "\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    print(\"Calculating embedding similarity...\")\n",
    "    resume_text = candidate_df[['career_objective', 'skills', 'major_field_of_studies', 'positions']].fillna('').astype(str).agg(' '.join, axis=1)\n",
    "    job_text = candidate_df[['job_position_name', 'educationaL_requirements', 'skills_required', 'responsibilities.1']].fillna('').astype(str).agg(' '.join, axis=1)\n",
    "    resume_emb = artifacts['embedding_model'].encode(resume_text.tolist())\n",
    "    job_emb = artifacts['embedding_model'].encode(job_text.tolist())\n",
    "    candidate_df['Embedding_Cosine_Similarity'] = [cosine_similarity([resume_emb[i]], [job_emb[i]])[0][0] for i in range(len(job_emb))]\n",
    "\n",
    "    candidate_df['svd_predicted_score'] = artifacts['mean_svd_score'] \n",
    "    \n",
    "    def calculate_skill_overlap(row):\n",
    "        try: \n",
    "            r_skills = set(str(row['skills']).lower().split()); j_skills = set(str(row['skills_required']).lower().split())\n",
    "            intersection = r_skills.intersection(j_skills); union = r_skills.union(j_skills)\n",
    "            return pd.Series([len(intersection), len(intersection) / len(union) if union else 0])\n",
    "        except: return pd.Series([0, 0.0])\n",
    "    candidate_df[['Skill_Overlap_Count', 'Skill_Jaccard_Score']] = candidate_df.apply(calculate_skill_overlap, axis=1)\n",
    "    \n",
    "    cluster_text = f\"{new_resume_dict.get('skills','')} {new_resume_dict.get('positions','')} experience {new_resume_dict.get('Resume_Years_Exp',0)}\"\n",
    "    candidate_df['Resume_Cluster_KMeans'] = artifacts['kmeans_model'].predict(artifacts['tfidf_cluster'].transform([cluster_text]))[0]\n",
    "    \n",
    "    candidate_df['university_encoded'] = candidate_df['first_university'].map(artifacts['university_map']).fillna(artifacts['university_map'].mean())\n",
    "\n",
    "\n",
    "    print(\"Feature matrix created successfully.\")\n",
    "    return candidate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "297bd127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_jobs(resume_data, artifacts):\n",
    "    \"\"\" Generates and displays recommendations from the loaded classification model. \"\"\"\n",
    "    feature_df = create_feature_matrix(resume_data, artifacts)\n",
    "    \n",
    "    final_features_list = [\n",
    "        'experience_years_required', 'Skill_Overlap_Count', 'Skill_Jaccard_Score', \n",
    "        'Resume_Years_Exp', 'Experience_Mismatch', 'Embedding_Cosine_Similarity', \n",
    "        'svd_predicted_score', 'Resume_Cluster_KMeans', 'highest_education_level', \n",
    "        'degree_type', 'university_encoded', 'gpa'\n",
    "    ]\n",
    "    # **Add gpa to the resume data to be passed**\n",
    "    feature_df['gpa'] = resume_data.get('gpa', 0.0)\n",
    "    \n",
    "    # Ensure the dataframe has columns in the correct order for the model\n",
    "    X_predict = feature_df[final_features_list]\n",
    "\n",
    "    predicted_probs = artifacts['model_pipeline'].predict_proba(X_predict)\n",
    "    high_match_index = list(artifacts['le'].classes_).index('High')\n",
    "    feature_df['high_match_probability'] = predicted_probs[:, high_match_index]\n",
    "    \n",
    "    cls_recs = feature_df.sort_values(by='high_match_probability', ascending=False).head(7)\n",
    "\n",
    "    print(\"\\n\\n\" + \"=\"*60 + \"\\n                     RECOMMENDATION RESULTS\\n\" + \"=\"*60)\n",
    "    print(\"\\n--- Top 7 Recommended Jobs (Ranked by 'High' Match Probability) ---\")\n",
    "    print(cls_recs[['job_position_name', 'high_match_probability']].to_string(index=False))\n",
    "    print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b525fdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing new resume and preparing 28 candidate pairs...\n",
      "Calculating embedding similarity...\n",
      "Feature matrix created successfully.\n",
      "\n",
      "\n",
      "============================================================\n",
      "                     RECOMMENDATION RESULTS\n",
      "============================================================\n",
      "\n",
      "--- Top 7 Recommended Jobs (Ranked by 'High' Match Probability) ---\n",
      "                         job_position_name  high_match_probability\n",
      "                  Senior Software Engineer                0.355618\n",
      "            Machine Learning (ML) Engineer                0.355618\n",
      "                         Marketing Officer                0.355618\n",
      "Manager- Human Resource Management (HRM)\\n                0.355618\n",
      "                     Data Science Engineer                0.355618\n",
      "                            Civil Engineer                0.355618\n",
      "    Full Stack Developer (Python,React js)                0.355618\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "if artifacts:\n",
    "    # ** EDIT THE VALUES IN THIS DICTIONARY TO TEST A NEW RESUME **\n",
    "    new_resume = {\n",
    "        'career_objective': 'A highly motivated data scientist seeking a challenging role to apply my skills in machine learning, Python, and cloud technologies.',\n",
    "        'skills': 'python, sql, machine learning, deep learning, pytorch, aws, docker, natural language processing',\n",
    "        'major_field_of_studies': 'Computer Science',\n",
    "        'positions': 'Machine Learning Engineer',\n",
    "        'degree_names': \"['Masters in Computer Science']\",\n",
    "        'Resume_Years_Exp': 3,\n",
    "        'gpa': 3.9,\n",
    "        'first_university': 'Carnegie Mellon University' # Use a known university for best results\n",
    "    }\n",
    "\n",
    "    # Generate and display recommendations\n",
    "    recommend_jobs(new_resume, artifacts)\n",
    "else:\n",
    "    print(\"\\nCould not run recommendations because artifacts were not loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423f664d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e1e7c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing new resume and preparing 28 candidate pairs...\n",
      "Calculating embedding similarity...\n",
      "Feature matrix created successfully.\n",
      "\n",
      "\n",
      "============================================================\n",
      "                     RECOMMENDATION RESULTS\n",
      "============================================================\n",
      "\n",
      "--- Top 7 Recommended Jobs (Ranked by 'High' Match Probability) ---\n",
      "                         job_position_name  high_match_probability\n",
      "                  Senior Software Engineer                0.355618\n",
      "            Machine Learning (ML) Engineer                0.355618\n",
      "                         Marketing Officer                0.355618\n",
      "Manager- Human Resource Management (HRM)\\n                0.355618\n",
      "                     Data Science Engineer                0.355618\n",
      "                            Civil Engineer                0.355618\n",
      "    Full Stack Developer (Python,React js)                0.355618\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "if artifacts:\n",
    "    # ** EDIT THE VALUES IN THIS DICTIONARY TO TEST A NEW RESUME **\n",
    "    new_resume_1 = {\n",
    "        'career_objective': 'A highly motivated software engineer seeking a challenging role to apply my coding skills in Web development, HTML, CSS, JS, and cloud technologies.',\n",
    "        'skills': 'Java, sql, HTML, CSS, JS, aws, docker, React JS, MongoDB',\n",
    "        'major_field_of_studies': 'Computer Science',\n",
    "        'positions': 'none',\n",
    "        'degree_names': \"['Masters in Computer Science']\",\n",
    "        'Resume_Years_Exp': 0,\n",
    "        'gpa': 3.9,\n",
    "        'first_university': 'DePaul University' # Use a known university for best results\n",
    "    }\n",
    "\n",
    "    # Generate and display recommendations\n",
    "    recommend_jobs(new_resume_1, artifacts)\n",
    "else:\n",
    "    print(\"\\nCould not run recommendations because artifacts were not loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d84f49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
